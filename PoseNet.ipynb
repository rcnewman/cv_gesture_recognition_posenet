{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoseNet",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcnewman/cv_gesture_recognition_posenet/blob/master/PoseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4afsWr4n0nJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cfcb6371-15eb-452d-92ae-853954ebe405"
      },
      "source": [
        "# PoseNet-python Notebook Source: https://colab.research.google.com/drive/1Ha7-lt-WwcCx961cuatjOzQ-7GLY91aQ#scrollTo=k_qlzhSXN3D7\n",
        "# install\n",
        "!git clone https://github.com/rcnewman/posenet-python.git #fork from https://www.github.com/rwightman/posenet-python \n",
        "%cd posenet-python\n",
        "!pip3 install tensorflow-gpu==1.15\n",
        "!pip3 install scipy\n",
        "!pip3 install pyyaml\n",
        "!pip3 install opencv-python\n",
        "!pip3 install ipykernel\n",
        "!pip3 install msgpack-numpy\n",
        "!pip3 install ffmpeg-python"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'posenet-python'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 143 (delta 11), reused 17 (delta 7), pack-reused 120\u001b[K\n",
            "Receiving objects: 100% (143/143), 42.86 KiB | 245.00 KiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n",
            "/content/posenet-python\n",
            "Collecting tensorflow-gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 43kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.18.5)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 42.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.35.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.31.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.12.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (49.6.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=127ea9cce9c5d778a8342b96503c870559bdfa54db303b8fa8f261bb5236bc76\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, gast, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (4.10.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (4.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (2.8.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (4.6.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (19.0.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel) (49.6.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel) (0.2.5)\n",
            "Collecting msgpack-numpy\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/50/8a49f3da7dca7baa9a5a12cd573af99b62746ba9298fa751e04a3c38c311/msgpack_numpy-0.4.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from msgpack-numpy) (1.18.5)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from msgpack-numpy) (1.0.0)\n",
            "Installing collected packages: msgpack-numpy\n",
            "Successfully installed msgpack-numpy-0.4.6.1\n",
            "Collecting ffmpeg-python\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfwBKf0BOAHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CONFIG\n",
        "max_pose_detections = 1\n",
        "min_pose_score = 0.25\n",
        "min_part_score = 0.25\n",
        "SAVE_KEYPOINTS = True\n",
        "DEBUG = False\n",
        "SAVE_VIDEO = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiAT_qmmcYFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ffmpeg    \n",
        "# Fix rotation, code from https://stackoverflow.com/questions/53097092/frame-from-video-is-upside-down-after-extracting\n",
        "def check_rotation(path_video_file):\n",
        "    # this returns meta-data of the video file in form of a dictionary\n",
        "    meta_dict = ffmpeg.probe(path_video_file)\n",
        "\n",
        "    # from the dictionary, meta_dict['streams'][0]['tags']['rotate'] is the key\n",
        "    # we are looking for\n",
        "    rotateCode = None\n",
        "    if 'rotate' in meta_dict['streams'][0]['tags']:\n",
        "      if int(meta_dict['streams'][0]['tags']['rotate']) == 90:\n",
        "          rotateCode = cv2.ROTATE_90_CLOCKWISE\n",
        "      elif int(meta_dict['streams'][0]['tags']['rotate']) == 180:\n",
        "          rotateCode = cv2.ROTATE_180\n",
        "      elif int(meta_dict['streams'][0]['tags']['rotate']) == 270:\n",
        "          rotateCode = cv2.ROTATE_90_COUNTERCLOCKWISE\n",
        "\n",
        "    return rotateCode\n",
        "\n",
        "def correct_rotation(frame, rotateCode):  \n",
        "    return cv2.rotate(frame, rotateCode) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6Q3yqU41lqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "30f0e0e7-7860-411c-f107-077b7a43958e"
      },
      "source": [
        "# PoseNet python sample program\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "import posenet\n",
        "import glob\n",
        "import msgpack\n",
        "import msgpack_numpy as m\n",
        "m.patch() #for handling numpy arrays w/ msgpack\n",
        "print('INIT:')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drivepath=\"/content/drive/My Drive/POSENET/\"\n",
        "# driveinfile = drivepath + 'input.mp4'\n",
        "video_path = glob.glob(drivepath + 'vids/*.mp4')\n",
        "save_video_path = drivepath + 'output_vids/'\n",
        "keypts_path = drivepath +'keypts/'\n",
        "# VideoReaderWriter\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "\n",
        "\n",
        "model = 101\n",
        "###scale_factor = 1.0\n",
        "scale_factor = 0.4\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print('MODEL-INIT:')\n",
        "    ####model_cfg, model_outputs = posenet.load_model(args.model, sess)\n",
        "    model_cfg, model_outputs = posenet.load_model(model, sess)\n",
        "    output_stride = model_cfg['output_stride']\n",
        "    start = time.time()\n",
        "    print('START:')\n",
        "    for vid in video_path:\n",
        "      cap = cv2.VideoCapture(vid)\n",
        "\n",
        "      rotateCode = check_rotation(vid)\n",
        "\n",
        "      incnt = 0\n",
        "      keypoints_save = []\n",
        "      if SAVE_VIDEO:\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        driveoutfile = save_video_path + os.path.basename(vid)\n",
        "        video = cv2.VideoWriter(driveoutfile, fourcc, fps, (width, height))\n",
        "      while True:\n",
        "          incnt = incnt + 1\n",
        "          try: input_image, draw_image, output_scale = posenet.read_cap(\n",
        "                  cap, scale_factor=scale_factor, output_stride=output_stride,rotate_code=rotateCode)\n",
        "          except:break\n",
        "          heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
        "              model_outputs,\n",
        "              feed_dict={'image:0': input_image}\n",
        "          )\n",
        "          pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multiple_poses(\n",
        "              heatmaps_result.squeeze(axis=0),\n",
        "              offsets_result.squeeze(axis=0),\n",
        "              displacement_fwd_result.squeeze(axis=0),\n",
        "              displacement_bwd_result.squeeze(axis=0),\n",
        "              output_stride=output_stride,\n",
        "              max_pose_detections=max_pose_detections,\n",
        "              min_pose_score=min_pose_score)\n",
        "\n",
        "          keypoint_coords *= output_scale\n",
        "\n",
        "          if SAVE_KEYPOINTS:\n",
        "            keypoints_save.append(keypoint_coords)\n",
        "          \n",
        "          if SAVE_VIDEO:\n",
        "            draw_image = posenet.draw_skel_and_kp(\n",
        "                    draw_image, pose_scores, keypoint_scores, keypoint_coords,\n",
        "                    min_pose_score=min_pose_score, min_part_score=min_part_score)\n",
        "\n",
        "            video.write(draw_image)\n",
        "\n",
        "          if incnt % 100 == 0:        \n",
        "              print(\"cnt=\", incnt, \"fps=\", incnt / (time.time() - start) )\n",
        "\n",
        "          if DEBUG:\n",
        "              #debug\n",
        "              for pi in range(len(pose_scores)):\n",
        "                  if pose_scores[pi] == 0.:\n",
        "                      break\n",
        "                  print('Pose #%d, score = %f' % (pi, pose_scores[pi]))\n",
        "                  for ki, (s, c) in enumerate(zip(keypoint_scores[pi, :], keypoint_coords[pi, :, :])):\n",
        "                      print('Keypoint %s, score = %f, coord = %s' % (posenet.PART_NAMES[ki], s, c))\n",
        "      \n",
        "      cap.release()\n",
        "\n",
        "      if SAVE_KEYPOINTS:\n",
        "        with open(keypts_path + os.path.basename(vid) + \"_pts.msgpack\", 'wb') as f:\n",
        "          packed = msgpack.packb(keypoints_save)\n",
        "          f.write(packed)\n",
        "\n",
        "      if SAVE_VIDEO:\n",
        "         video.release()\n",
        "\n",
        "print('END:')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INIT:\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "MODEL-INIT:\n",
            "START:\n",
            "cnt= 100 fps= 15.448704644128195\n",
            "cnt= 200 fps= 18.98886463489525\n",
            "END:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu7uJWCzlXyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classes ---------------------------------------------------------------------\n",
        "class KerasBatchGenerator(object):\n",
        "\n",
        "    def __init__(self, file_list, batch_size,steps,jump=1):\n",
        "        self.file_list = file_list\n",
        "        self.batch_size = batch_size\n",
        "        self.steps=steps\n",
        "        self.current_idx = 0\n",
        "        self.current_file=0\n",
        "        self.data=None\n",
        "        self.limit=0\n",
        "        self.gestures=10\n",
        "        self.jump=jump\n",
        "        self.keypoint_number=17*2\n",
        "    def generate(self):\n",
        "        # Load June 1st data.\n",
        "        with open(self.file_list[self.current_file], \"rb\") as data_file:\n",
        "            byte_data = data_file.read()\n",
        "        self.data = msgpack.unpackb(byte_data)\n",
        "        self.limit = len(self.data)\n",
        "        while True:\n",
        "            \n",
        "            # Build empty matricies.\n",
        "            #y = np.zeros((self.batch_size, self.steps))\n",
        "            y = np.zeros((self.batch_size, self.gestures))\n",
        "            keypoints = np.zeros((self.batch_size, self.steps, self.keypoint_number))\n",
        "\n",
        "            # Iterate through all files.\n",
        "            for i in range(self.batch_size):\n",
        "                if self.current_idx + self.steps + 1 >= self.limit:\n",
        "                    self.current_file += 1\n",
        "                    if(self.current_file >= len(self.file_list)):\n",
        "                        self.current_file =0\n",
        "                    with open(self.file_list[self.current_file], \"rb\") as data_file:\n",
        "                        byte_data = data_file.read()\n",
        "                    self.data = msgpack.unpackb(byte_data)\n",
        "                    self.limit = len(self.data)\n",
        "                    self.current_idx = 0\n",
        "                for k in range(self.steps):\n",
        "                    keypoints[i][k][:] = self.data[self.current_idx+k][0].flatten()\n",
        "\n",
        "                #### we need to decide on a syntax for the gesture time stamps and use it in label generation\n",
        "                self.current_idx += self.jump\n",
        "            x = keypoints\n",
        "            return x, y\n",
        "            \n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agMQqHEisGcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "4d268452-5402-489c-993c-a213a04c9ad7"
      },
      "source": [
        "import keras\n",
        "# Global Variables ------------------------------------------------------------\n",
        "batch_size = 64\n",
        "steps = 24\n",
        "num_steps = 100\n",
        "num_epochs = 200\n",
        "num_training = 10\n",
        "jump=8\n",
        "keypoint_number=17*2\n",
        "lstm_cels=keypoint_number\n",
        "gesture_number=10\n",
        "\n",
        "training_keypoints=[\"./data.msgpack\" ]\n",
        "valid_keypoints=[\"./data.msgpack\" ]\n",
        "\n",
        "train_data_generator = KerasBatchGenerator(training_keypoints, batch_size, steps,jump)\n",
        "valid_data_generator = KerasBatchGenerator(valid_keypoints, batch_size, steps,jump)\n",
        "\n",
        "# Set Up GPU ------------------------------------------------------------------\n",
        "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\";\n",
        "\n",
        "# Build Models ----------------------------------------------------------------\n",
        "save_location='/content/drive/My Drive/POSENET/Experiments/ALL_LSTM_01'\n",
        "saveFiles = ([name for name in os.listdir(save_location)])\n",
        "initial_epoch = len(saveFiles)\n",
        "if(len(saveFiles) > 0):\n",
        "    if(len(saveFiles) > 9):\n",
        "        model = tf.keras.models.load_model(save_location+\"/model-\"+str(len(saveFiles))+\".hdf5\")\n",
        "    else:\n",
        "        model = tf.keras.models.load_model(save_location+\"/model-0\"+str(len(saveFiles))+\".hdf5\")\n",
        "    print(model.summary(90))\n",
        "else:\n",
        "    print(\"else\")\n",
        "    \n",
        "    # Build input shapes.\n",
        "    keypointInput = keras.layers.Input(shape=(steps, keypoint_number))\n",
        "\n",
        "    \n",
        "    # Build lstm layers.\n",
        "    masking_layer = layers.Masking(mask_value=0)(keypointInput)\n",
        "    keypoint = keras.layers.LSTM(lstm_cels, return_sequences=False)(masking_layer)\n",
        "    # Build dense layer\n",
        "    gesture = keras.layers.TimeDistributed(keras.layers.Dense(gesture_number, activation='sigmoid'))(keypoint)\n",
        "    \n",
        "    \n",
        "    model = keras.Model(inputs=keypointInput, outputs=gesture)\n",
        "    print(model.summary(90))\n",
        "    \n",
        "# Weight and train model.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',metrics=['accuracy','categorical_crossentropy'])\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=save_location+'/concat-{epoch:02d}.hdf5', verbose=1)\n",
        "model.fit_generator(train_data_generator.generate(), 10000, num_epochs,\n",
        "                    validation_data=valid_data_generator.generate(),validation_steps=1000,\n",
        "                    callbacks=[checkpointer] ,\n",
        "                    shuffle=False,initial_epoch=initial_epoch)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-2ea1b41e316a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Global Variables ------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyBPBmZu1qww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "\n",
        "# TODO: Actually set-up the model beyond skeleton\n",
        "\n",
        "\n",
        "#num_gestures = 11 #10 gestures + null\n",
        "#batch = 32\n",
        "#num_epochs = 3\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Input()\n",
        "# model.add(LSTM())\n",
        "# model.add(LSTM())\n",
        "# model.add(Dense(num_gestures, activation='softmax'))\n",
        "# model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# X_train, X_valid, Y_train, Y_valid = subject_wise_split(X,Y)\n",
        "\n",
        "# model.fit(X_train, Y_train, batch_size=batch, epochs=num_epochs,verbose=1)\n",
        "\n",
        "# score, acc = model.evaluate(X_valid,Y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}